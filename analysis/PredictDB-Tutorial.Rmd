---
title: "PredictDB-Tutorial"
author: "Tyson Miller & Festus Nyasimi"
date: "8/21/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(dplyr)
library(RSQLite)
```


## Download data from [here](https://uchicago.app.box.com/folder/118354657358)

# Data
  * Gene expression - YRI_expression_data.txt
  Normalized gene expression in .txt format. 
  * SNP annotation - geuvadis.annot.txt
  * Gene annotation - gencode.v12.annotation.gtf
  * Genotype - geuvadis.snps.dosage.txt
  
Loading the data:
```{r}
gene_exp = read.table(file = "../data/YRI_expression_data.txt", header = TRUE, sep = "\t" )
```

```{r}
##Dropping columns we don't need in the gene expression dataframe
gene_exp = gene_exp[-c(1, 3, 4)]
```

```{r}
gene_exp = rename(gene_exp, 'Gene_Name' = Gene_Symbol)
```



Gene annotation. Use the script parse_gtf.py with first argument the path to the annotation file, and second argument the file output. This will create a new tab-delimited text file from the gtf file with only the necessary features for the model creation.
```{bash}
../code/parse_gtf.py ../data/'gencode.v12.annotation.gtf' ../output/'gene_annot.parsed.txt'
```


This will create an RDS object out of the gene annotation file text file --> FOR OLDER VERSION 
```{bash}
#Rscript ../PredictDB-Scripts/geno_annot_to_RDS.R ../output/'gene_annot.parsed.txt' ../output/'gene_annot.RDS'
```

2. SNP Annotation - First we will rename the columns to fit the pipeline:
```{bash}
## Trying to think of a better way to automate this

sed -e 's/Chr/chromosome/g' -e 's/Ref_b37/ref_vcf/g' -e 's/Alt/alt_vcf/g' ../data/geuvadis.annot.txt > ../data/snp_annotation.txt

```


Then we want to split this file by chromosome and turn them into .RDS format. We will end up with 22 separate .RDS files corresponding to the 22 chromosomes.

```{bash}
../code/split_snp_annot_by_chr.py ../data/geuvadis.annot.txt ../output/snp_annot
```


Now we will turn all of these SNP annotation txt files into .RDS format so they can be used in the model. --> FOR OLDER VERSION

```{bash}
# Rscript ../PredictDB-Scripts/snp_annot_to_RDS.R ../output/'snp_annot.chr'
```

3. Genotype File - Again, first we rename the columns to fit the pipeline.
```{bash}
sed 's/Id/varID/g' ../data/geuvadis.snps.dosage.txt > ../data/genotype.txt
```


Then we want to also split this by chromosome:
```{bash}
../code/split_genotype_by_chr.py ../data/geuvadis.snps.dosage.txt ../output/genotype
```

Creating the PEER covariates - We want to regress out covariate factors from the gene expression data. We want to generate PEER factors https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3398141/ and use those as our covariates and then perform a multiple linear regression for each gene in our gene expression matrix and then save the residuals from the regressions as our new expressions.

There is a description of how to download the PEER tool here : https://github.com/hakyimlab/peer

First we must transpose the gene expression matrix

```{r}
n = gene_exp$Gene_Name
gene_exp_transpose <- as.data.frame(t(gene_exp[,-1]))
colnames(gene_exp_transpose) <- n
```

Then we must turn this dataframe into a csv file to be used by the PEER tool:
```{r}
write.table(gene_exp_transpose, file = '../output/gene_exp.csv', sep = ",", col.names = TRUE, row.names = FALSE)
```

Now we use the PEER tool on the csv file to generate PEER factors. According to GTEx protocol, If the number of samples is greater than or equal to 350, we use 60 PEER factors. If the number of samples is between 250 and 350, we use 45. Between 150 and 250, we use 30, and less than 150 we use 15. For this study, the number of samples is 463 so we will use 60 PEER factors.
```{bash}
## Note this takes a LONG time. Maybe we should skip this for now especially when testing and debugging code. I even tried to run it for just 1 or 5 PEER factors and it takes forever. 

peertool -f '../output/gene_exp.csv' -n 3 --has_header -o ../output/peer_out
```

Now we read in the output of the PEER tool which is our covariate matrix.
```{r}
peer_factors = read.csv(file = "../output/peer_out/X.csv", header = FALSE)

#Set the column names for the PEER factors (covariates) as the subject IDs
colnames(peer_factors) = rownames(gene_exp_transpose)
```

We must write the covariates as a .txt file because that is what the pipeline takes
```{r}
write.table(peer_factors, file = "../output/covariates.txt", sep = "\t",
            row.names = TRUE)
```


Now we run our multiple linear regression and set the matrix of the residuals as our new expressions
```{r}
## This is making a copy of the gene expression transposed dataframe so that we can replace the values with the residuals of the multiple linear regressions.

expression = gene_exp_transpose
```

```{r}
# This loops through all the columns of the transposed gene expression which correspond to each gene and for each gene it runs  linear regression on the PEER factor covariates. Then it sets the residuals to the new expression for that gene.
for (i in 1:length(colnames(gene_exp_transpose))) {
    fit = lm(gene_exp_transpose[,i] ~ t(as.matrix(peer_factors)))
    expression[,i] <- fit$residuals
  }
```

Write out the transformed expression
```{r}
# Write out the final expression file
write.table(expression, file = "../output/transformed_expression.txt", sep = "\t",
            row.names = TRUE)
```


Tutorial for gtex v7 pipeline:


First you must change the paths in the file 'gtex_tiss_chrom_training.R' to fit the paths of the data in your directories. Also make it so that it only takes chrom as an argument instead of tissue if it doesn't already do that.

```{bash}
mkdir -p ../summary ../covariances ../weights
```


Then you run this:
```{bash}
# This script invokes other scripts to train the model. Repeat this step for all the 22 chromosomes.
#Use the for loop below to run all by uncomenting the line below for demo I will run one chromosome(21)
#for i in {1..22}; do Rscript ../code/gtex_tiss_chrom_training.R $i; done

Rscript ../code/gtex_tiss_chrom_training.R 21
```

Make dir for the database
```{bash}
mkdir -p ../dbs
```

Create database once we have our model summaries we combine them into a single file then create a database

```{r}
"%&%" <- function(a,b) paste(a,b, sep='')

driver <- dbDriver('SQLite')

model_summaries <- read.table('../summary/Model_training_chr1_model_summaries.txt',                                                       header = T, stringsAsFactors = F)
tiss_summary <- read.table('../summary/Model_training_chr1_summary.txt',                                                         header = T, stringsAsFactors = F)
  
n_samples <- tiss_summary$n_samples
  
for (i in 2:22) {
  model_summaries <- rbind(model_summaries,
                            read.table('../summary/Model_training_chr'%&%as.character(i) %&% '_model_summaries.txt', header = T, stringsAsFactors = F))
  tiss_summary <- rbind(tiss_summary,
                             read.table('../summary/Model_training_chr' %&% as.character(i) %&% '_summary.txt', header = T, stringsAsFactors = F))
  
}
  
model_summaries <- rename(model_summaries, gene = gene_id)

conn <- dbConnect(drv = driver, '../dbs/gtex_v7_models.db')
dbWriteTable(conn, 'model_summaries', model_summaries, overwrite = TRUE)
dbExecute(conn, "CREATE INDEX gene_model_summary ON model_summaries (gene)")

# Weights Table -----
weights <- read.table('../weights/Model_training_chr1_weights.txt', header = T,                                                                 stringsAsFactors = F)
for (i in 2:22) {
  weights <- rbind(weights,
                       read.table('../weights/Model_training_chr' %&% as.character(i) %&% '_weights.txt', header = T, stringsAsFactors = F))
  
}
  
weights <- rename(weights, gene = gene_id)
dbWriteTable(conn, 'weights', weights, overwrite = TRUE)
dbExecute(conn, "CREATE INDEX weights_rsid ON weights (rsid)")
dbExecute(conn, "CREATE INDEX weights_gene ON weights (gene)")
dbExecute(conn, "CREATE INDEX weights_rsid_gene ON weights (rsid, gene)")
# Sample_info Table ----
sample_info <- data.frame(n_samples = n_samples, population = 'yoruba')
dbWriteTable(conn, 'sample_info', sample_info, overwrite = TRUE)
  
# Construction Table ----
construction <- tiss_summary %>%
                    select(chrom, cv_seed) %>%
                    rename(chromosome = chrom)
dbWriteTable(conn, 'construction', construction, overwrite = TRUE)

dbDisconnect(conn)

```

Filter the databases to gen significant values
```{r}
unfiltered_db <- '../dbs/gtex_v7_models.db'
filtered_db <- '../dbs/gtex_v7_models_filtered_signif.db'

driver <- dbDriver("SQLite")

in_conn <- dbConnect(driver, unfiltered_db)
out_conn <- dbConnect(driver, filtered_db)
model_summaries <- dbGetQuery(in_conn, 'select * from model_summaries where zscore_pval < 0.05 and rho_avg > 0.1')
model_summaries <- model_summaries %>% 
                    rename(pred.perf.R2 = rho_avg_squared, genename = gene_name, pred.perf.pval = zscore_pval, n.snps.in.model = n_snps_in_model)
model_summaries$pred.perf.qval <- NA
dbWriteTable(out_conn, 'extra', model_summaries, overwrite = TRUE)
construction <- dbGetQuery(in_conn, 'select * from construction')
dbWriteTable(out_conn, 'construction', construction, overwrite = TRUE)
sample_info <- dbGetQuery(in_conn, 'select * from sample_info')
dbWriteTable(out_conn, 'sample_info', sample_info, overwrite = TRUE)
weights <- dbGetQuery(in_conn, 'select * from weights')
weights <- weights %>% filter(gene %in% model_summaries$gene) %>% rename(eff_allele = alt, ref_allele = ref, weight = beta)
dbWriteTable(out_conn, 'weights', weights, overwrite = TRUE)
dbExecute(out_conn, "CREATE INDEX weights_rsid ON weights (rsid)")
dbExecute(out_conn, "CREATE INDEX weights_gene ON weights (gene)")
dbExecute(out_conn, "CREATE INDEX weights_rsid_gene ON weights (rsid, gene)")
dbExecute(out_conn, "CREATE INDEX gene_model_summary ON extra (gene)")
dbDisconnect(in_conn)
dbDisconnect(out_conn)
```

